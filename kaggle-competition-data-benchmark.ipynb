{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Overview\n",
    "In this notebook I am going to grab the data that will be used for the example Kaggle competition and also develop a working machine learning model (this is required so that the competition has a \"benchmark\"). As always one of the most difficult parts of this process is finding a good data set, but I'm going to be focusing on the other components of the process -- getting a working Kaggle competition that can be hosted in a classroom."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from os import path\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get the IRIS Data\n",
    "Since we're just showing how one can get a Kaggle competition up and running, the classic \"Iris\" data built by Ronald Fisher in the 1930s will suffice. To make this a workable data set for Kaggle though we need two conditions to hold:\n",
    "1. We need to be able to upload the data to Kaggle's server (hence we have to save the data to disk)\n",
    "2. There must be a training and a testing set.\n",
    "\n",
    "Regarding the second point, one additional point is the target for the test set, referred to as $\\mathbf{y}_{\\text{Te}}$ must be separate from the data you upload to the server.\n",
    "\n",
    "We're going to execute those steps and save the data to disk so we can start working setting up the Kaggle competition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = load_iris(return_X_y=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we have to create the train-test partition\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.25, random_state=17\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally we have to save the data to disk (they will be placed in the \"data\" folder in this repository). A large number of file formats are valid. For example, in my competition I used an .h5 file, a format that allows a large quantity of data to be stored with low memory footprint, but for now we'll just use .csv. In general though, it doesn't matter, but I would recommend making it an easier format to download and work with during a session because the .h5 experiment required me to do a bit of extra work so the students understood how to work with the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "fnames = ['X_train.csv', 'X_test.csv', 'y_train.csv', 'y_test.csv']\n",
    "arrs = [X_train, X_test, y_train, y_test]\n",
    "\n",
    "# Convert the data matrices into pandas DataFrames\n",
    "X_train = pd.DataFrame(X_train)\n",
    "X_test = pd.DataFrame(X_test)\n",
    "\n",
    "# Save the data matrices to disk\n",
    "fnames = ['X_train.csv', 'X_test.csv']\n",
    "arrs = [X_train, X_test]\n",
    "[arr.to_csv(path.join('data', fname), index=False)\n",
    " for (arr, fname) in zip(arrs, fnames)]\n",
    "\n",
    "# Convert the training vector into a DataFrame\n",
    "y_train = pd.DataFrame(y_train)\n",
    "y_train.to_csv('data/y_train.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have saved all of the data to disk. We're going to now shift gears to getting the Kaggle competition up and running. We'll have to return to this notebook to build our benchmark for the competition, but that isn't until much later in the process."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Making a Valid Solution and Submission File\n",
    "Kaggle requires that we have a valid solution file and a valid submission file. For metric of \"CategorizationAccuracy\" it has the expected format (for example)\n",
    "\n",
    "|Id | Category|\n",
    "| --| --------|\n",
    "| 1 | 0       |\n",
    "| 2 | 1       |\n",
    "\n",
    "and so forth. We are going to convert the `y_test` to meet this standard and also generate a valid submission file.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a valid solution file\n",
    "nsamples = len(y_test)\n",
    "id_col = np.arange(nsamples)\n",
    "\n",
    "solution_file = pd.DataFrame({\"Id\": id_col,\n",
    "                              \"Category\": y_test})\n",
    "\n",
    "# Make a valid submission file\n",
    "nlabels = len(np.unique(y_test))\n",
    "rng = np.random.RandomState(17)\n",
    "rand_pred = rng.randint(low=0, high=nlabels, size=nsamples)\n",
    "\n",
    "submission_file = pd.DataFrame({\"Id\": id_col,\n",
    "                                \"Category\": rand_pred})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the files to disk\n",
    "solution_file.to_csv('data/solution_file.csv', index=False)\n",
    "submission_file.to_csv('data/submission_file.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Running the Benchmark\n",
    "For the benchmark, I am just going to use the randomly generated submission file. Of course in real competition you should probably provide a better benchmark, but this is fine for this example."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
